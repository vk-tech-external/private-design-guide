# {heading(Роли серверов)[id=arch_server_roles]}

<!--- #todo на раздел **Узлы управления** → **Обязательные узлы управления** есть ссылка в ПМИ Private Cloud. -->

Все серверы, на которые производится установка {var(sys2)}, делятся на три типа:

* Узлы управления (Control Plane).
* Узлы прикладных сервисов (Application services Plane)
* Узлы рабочих нагрузок (Data Plane).

В рамках каждого типа серверы выполняют специфические роли, которые предъявляют различные требования к их производительности, количеству и правилам масштабирования.

Рекомендуется использовать серверы с процессорами актуального поколения. Допускается использование процессоров как Intel Xeon, так и AMD EPYC.

<warn>

{var(sys1)} поддерживает процессоры с архитектурой x86_64 (AMD64).

</warn>

Не рекомендуется использовать аппаратные RAID-контроллеры — это правило действительно для всех ролей. Причины: более низкая, чем у программных решений, скорость на используемых на {var(sys3)} уровнях массивов и более сложное восстановление данных в случае отказа.

## {heading(Узлы управления)[id=arch_control_nodes]}

На серверах, относящихся к слою управления, выполняются службы, отвечающие за управление компонентами {var(sys2)} или обеспечивающие их функционирование. Часть ролей слоя управления является опциональной или может быть заменена на оборудование, имеющееся в наличии у Заказчика.

### {heading(Обязательные узлы управления)[id=arch_required_control_nodes]}

<!--- #todo на раздел есть ссылка в ПМИ Private Cloud. -->

#### {heading(Контроллеры)[id=arch_controllers]}

На управляющих узлах (контроллерах) размещаются основные службы {var(sys2)} и их API (Nova, Cinder, Glance и прочие). Также на серверах с этой ролью размещаются служебные компоненты (служебный кластер Kubernetes, RabbitMQ, Kafka, MariaDB и прочие). Если в документации для компонента не указано иное, компоненты размещаются в служебном кластере Kubernetes.

В крупных инсталляциях допустимо выделять контроллеры для расширения служебного кластера Kubernetes и/или кластеров служебных БД. Рекомендованная конфигурация дополнительных контроллеров соответствует основной конфигурации.

Минимальное количество контроллеров в инсталляции — 3, увеличение количества контроллеров производится согласно разделу {linkto(../../design_principles_main/design_control_loop_server_calculations#calculations_controller_scaling_principles)[text=%text]}.

#### {heading(Узел развертывания/репозитория)[id=arch_deployment_repository_node]}

Эта роль представлена единственным сервером и используется начиная с самых начальных этапов развертывания {var(sys2)}. В отличие от остальных ролей, этот сервер должен предоставляться Заказчиком с уже установленной ОС.

Основные задачи деплой-сервера:

* Запуск механизмов развертывания {var(sys2)}.
* Изменение настроек, обновление и восстановление {var(sys2)}.
* Подготовка серверов к включению в состав {var(sys2)}.
* Размещение сервиса репозитория пакетов и образов компонентов {var(sys2)}.

<err>

Деплой-ноду нельзя отключать после развертывания {var(sys2)}.

</err>

Требуется только 1 сервер. Допустимо дублирование роли. Необходимо выполнять регулярное резервное копирование деплой-ноды с периодическим контролем корректности его восстановления.

### {heading(Служебные узлы управления)[id=arch_service_control_nodes]}

#### {heading(Узлы мониторинга и логирования)[id=arch_monitoring_and_logging_nodes]}

На узлах с этой ролью размещаются сервисы мониторинга и логирования.

Мониторинг реализован на базе Zabbix с использованием MySQL для хранения данных.

Логирование реализовано на связке OpenSearch или OpenSearch Dashboard с Apache Kafka и Filebeat.

Особенностью серверов этой роли является высокая зависимость нагрузки от объема и состава {var(sys2)}, а также интенсивности управляющих воздействий на {var(sys3)}. Пример: создание/удаление сущностей.

Для размещения этой роли допустимо использовать виртуальные машины.

По умолчанию рекомендуется закладывать 1 сервер. При большом размере инсталляции может потребоваться увеличение количества узлов до трех.

## {heading(Узлы прикладных сервисов)[id=arch_application_service_nodes]}

На серверах, относящихся к слою прикладных сервисов, размещаются подсистемы, отвечающие за дополнительные сервисы, такие как Cloud Monitoring, Cloud Logging, Cloud Audit и Cloud Alerting. На текущий момент к узлам прикладных сервисов относятся единственная роль EVH (EventHouse).

На узлах с ролью EVH размещаются кластеры ClickHouse, Victoria Metrics и Kafka, которые являются компонентами подсистем Cloud Monitoring, Cloud Logging, Cloud Audit и Cloud Alerting. Минимальное количество серверов EVH в инсталляции — 3. Допустимо совмещать данную роль с контроллерами.

Данная роль является опциональной и может быть исключена из инсталляции.

## {heading(Узлы рабочих нагрузок)[id=arch_workload_nodes]}

На серверах, относящихся к слою рабочих нагрузок (Data Plane), выполняются компоненты, отвечающие за выполнение рабочих нагрузок, и непосредственно рабочая нагрузка.

### {heading(Вычислительные узлы)[id=arch_compute_nodes]}

Вычислительные узлы (Compute Nodes) — основные серверы, которые используются для запуска рабочих нагрузок пользователей. Эти узлы поставляются с гипервизором KVM.

Рекомендованные конфигурации отличаются высокой вариативностью в зависимости от требований Заказчика. Возможно применение различных конфигураций в рамках роли с объединением одинаковых серверов в агрегаты.

Общая рекомендация: использовать процессоры с максимальным количеством ядер при заданной частоте. Объем памяти зависит от требований к максимальному объему памяти в типе ВМ и допустимых коэффициентов переподписки.

В инсталляции {var(sys2)} должен быть минимум 1 узел. Чтобы полностью использовать функциональность {var(sys2)} («живую» миграцию, Affinity и Anti-Affinity) необходимо минимум 3 узла. Допустимо увеличивать количество вычислительных узлов по одному серверу.

При расчете рекомендуется закладывать резерв мощности в 10–15% (но не менее одного узла). Это обеспечит бесперебойную работу системы в случае выхода из строя или планового обслуживания любого из узлов.

### {heading(Сетевые узлы)[id=arch_network_nodes]}

На сетевых узлах (Network nodes) размещаются компоненты, реализующие основные сетевые функции (SNAT, DHCP, DNS). Эти узлы можно комбинировать с узлами контроллера.

Минимальное количество — 2 узла (для обеспечения отказоустойчивости). Далее возможно последовательное добавление по одному узлу. Рекомендуемое количество — 200 виртуальных сетей на один узел. Рекомендуется сохранять запас 10-15%, чтобы обеспечить работоспособность сети при обновлении или выходе из строя более одного сервера.

### {heading(Узлы Ceph)[id=arch_ceph_nodes]}

На узлах с ролью `Ceph` устанавливается программно-определяемое хранилище Ceph. {var(sys1)} использует Ceph версии Octopus. В качестве накопителей используются твердотельные диски.

Минимальное количество узлов в кластере — 3. Кластер масштабируется добавлением узлов кратно трем. Максимальное количество узлов в кластере — 9. Если требуется большая емкость дискового хранилища, формируется несколько кластеров Ceph.

### {heading(High-IOPS Storage)[id=arch_high_iops_storage]}

Узлы High-IOPS Storage — это хранилище, реализованное на базе выделенных физических серверов стандартной архитектуры, функционирующих как одиночные экземпляры блочного хранилища.

Высокая производительность и минимальные задержки операций ввода-вывода обеспечиваются за счет использования NVMe-дисков. Данный вид хранилища не обеспечивает механизмов защиты данных от выхода из строя серверного узла целиком. При этом, с помощью механизмов «горячего» резервирования реализуется защита функционирования сервиса на уровне базовых аппаратных компонентов (электропитание, подключение в сети передачи данных и прочее). Для защиты пользовательских данных используется механизм репликации блочных данных с помощью технологии LVM Mirror.

<err>

В случае выхода из строя сервера, данные будут недоступны до его восстановления. В случае отказа более двух дисков, в зеркале возможна потеря данных.

</err>

Количество узлов High-IOPS Storage в инсталляции может быть произвольным.

### {heading(Узлы Внешних СХД)[id=arch_nvme_nodes]}

Узлы внешней СХД — внешнее по отношению к {var(sys3)} облачное хранилище, основанное на технологии iSCSI. С помощью узлов внешней СХД доступно создание облачного хранилища на СХД сторонних производителей.

Производительность ввода/вывода и отказоустойчивость виртуальных машин зависят от:

* Производительности ввода/вывода и отказоустойчивости подключенной СХД.
* Пропускной способности и надежности сети.

Подключение СХД организовано с помощью типов серверов:

* Управляющие узлы (Control Nodes), отвечают за взаимодействие с СХД и выделение мостов для виртуальных машин с использованием технологии LVM. 
* Вычислительные узлы (Compute Nodes), обеспечивают прямое подключение виртуальных машин к СХД для организации постоянного хранения данных.

<info>

В {var(sys2)} можно подключить до трех типов внешних СХД с разными показателями производительности и отказоустойчивости (например: HDD, SSD, Prod-SSH).

</info>




